{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1L_AdOVmBgjTh0cCuMmGDbzJo4N8LDPsQ","authorship_tag":"ABX9TyPBuga4X65SaiXDYY5eRiEI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CRAWLING DATA TWITTER MENGGUNAKAN TWINT"],"metadata":{"id":"BmZOwWw9QIGT"}},{"cell_type":"markdown","source":["## Mount Google Drive"],"metadata":{"id":"V0Cbof6zQlQ5"}},{"cell_type":"markdown","source":["Moount Google Drive dengan Google Collab"],"metadata":{"id":"-xOSTPIXYT2V"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"BOAqTweeGoVJ","executionInfo":{"status":"ok","timestamp":1663043666701,"user_tz":-420,"elapsed":4031,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"77a8e02f-c85d-4efc-f8fc-f150e3c56dc7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Masuk ke direktori projek Web Mining"],"metadata":{"id":"Jv8AhLtsYZwv"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Web Mining"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulEQVxcCHFWj","executionInfo":{"status":"ok","timestamp":1663084460195,"user_tz":-420,"elapsed":673,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"57d4452b-4eb5-487e-a240-074b545c5d61"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Web Mining\n"]}]},{"cell_type":"markdown","source":["## Intalasi Twint"],"metadata":{"id":"ljVyc1BURpSI"}},{"cell_type":"markdown","source":["Langkah awal clone terlebih twint dari GitHub TwintProject, lalu kita masuk kedalam folder yang sudah kita clone tadi. Tinggal jalankan script dibawah untuk memasang Twint ke projek kita"],"metadata":{"id":"6Dzl4NEIRz-6"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"oc_MRaRa_8R0","executionInfo":{"status":"ok","timestamp":1663043672750,"user_tz":-420,"elapsed":6086,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"5a6a4755-d5e5-49ef-fcbc-14e30254ec7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'twint' already exists and is not an empty directory.\n","/content/drive/MyDrive/Web Mining/twint\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/drive/MyDrive/Web Mining/twint\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.7.0)\n","Requirement already satisfied: aiodns in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (3.0.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.6.3)\n","Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (2.1.7)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (0.6)\n","Requirement already satisfied: elasticsearch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (8.4.1)\n","Requirement already satisfied: pysocks in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.7.1)\n","Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.5)\n","Requirement already satisfied: aiohttp_socks<=0.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (0.4.1)\n","Requirement already satisfied: schedule in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.1.0)\n","Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.17.0)\n","Requirement already satisfied: fake-useragent in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.1.11)\n","Requirement already satisfied: googletransx in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.4.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (2022.2.1)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp_socks<=0.4.1->-r requirements.txt (line 9)) (22.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (6.0.2)\n","Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (3.0.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->-r requirements.txt (line 1)) (1.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->-r requirements.txt (line 8)) (1.15.0)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 1)) (4.1.1)\n","Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from aiodns->-r requirements.txt (line 2)) (4.2.2)\n","Requirement already satisfied: cffi>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pycares>=4.0.0->aiodns->-r requirements.txt (line 2)) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.5.0->pycares>=4.0.0->aiodns->-r requirements.txt (line 2)) (2.21)\n","Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r requirements.txt (line 6)) (8.4.0)\n","Requirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->-r requirements.txt (line 6)) (1.26.12)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elastic-transport<9,>=8->elasticsearch->-r requirements.txt (line 6)) (2022.6.15)\n","Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->-r requirements.txt (line 11)) (1.52)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from googletransx->-r requirements.txt (line 13)) (2.28.1)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->googletransx->-r requirements.txt (line 13)) (2.1.1)\n","Building wheels for collected packages: twint\n","  Building wheel for twint (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for twint: filename=twint-2.1.21-py3-none-any.whl size=38871 sha256=e6baaca87eb0e23834db29c9919782c6e4ed248bb5438becf452504c38cb73a6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ju_eqx_8/wheels/ce/ec/44/07ea4188fed75e2ea686655fde89c7e4deabe23f76daf75d4e\n","Successfully built twint\n","Installing collected packages: twint\n","  Attempting uninstall: twint\n","    Found existing installation: twint 2.1.21\n","    Uninstalling twint-2.1.21:\n","      Successfully uninstalled twint-2.1.21\n","Successfully installed twint-2.1.21\n"]}],"source":["!git clone --depth=1 https://github.com/twintproject/twint.git\n","%cd twint\n","!pip3 install . -r requirements.txt"]},{"cell_type":"markdown","source":["Pasang aiohttp berguna menyediakan Web-server dengan middlewares dan plugable routing "],"metadata":{"id":"P6POdEkySWTZ"}},{"cell_type":"code","source":["!pip install aiohttp==3.7.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"E4yGwQBGCXtB","executionInfo":{"status":"ok","timestamp":1663043677187,"user_tz":-420,"elapsed":4451,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"bbcb3c09-df79-4e78-e268-11738f246720"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: aiohttp==3.7.0 in /usr/local/lib/python3.7/dist-packages (3.7.0)\n","Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (3.0.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (22.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (1.8.1)\n","Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (3.0.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.0) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.0) (4.1.1)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.0) (2.10)\n"]}]},{"cell_type":"markdown","source":["Pasang nest-asyncio untuk runtime serentak dalam noteboook"],"metadata":{"id":"vfp-bpTSUIdQ"}},{"cell_type":"code","source":["!pip install nest-asyncio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"rFYCDUQCV7d_","executionInfo":{"status":"ok","timestamp":1663043680690,"user_tz":-420,"elapsed":3515,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"37b787bc-02ab-48ec-fb0b-9db9268b16e6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.5)\n"]}]},{"cell_type":"markdown","source":["Import nest-asyncio dan juga twint agar bisa melakukan crawling data di twitter"],"metadata":{"id":"Tb5zS5rsUzYS"}},{"cell_type":"code","source":["import nest_asyncio\n","nest_asyncio.apply()\n","import twint"],"metadata":{"id":"JTCcL5SyCyE5","executionInfo":{"status":"ok","timestamp":1663043681878,"user_tz":-420,"elapsed":1200,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Crawling data twitter "],"metadata":{"id":"IbsW2Wn9VNpY"}},{"cell_type":"markdown","source":["Jadi disini kita akan melakukan crawling data yang diunduh dari server twitter. Cara ini cukup simpel, cepat dan gak ribet, karena kita gak perlu punya akun twitter, gak perlu API dan tanpa limitasi juga. Kita hanya perlu sebuah tool yang bernama **twint**. \n",">**Twint** adalah sebuah tools yang digunakan untuk melakukan scrapping dari aplikasi twitter yang disetting secara khusus menggunakan bahasa pemrograman Python. Twint dapat kita gunakan dan jalankan tanpa harus menggunakan API dari Twitter itu sendiri, dengan kapasitas scrapping data maksimalnya adalah 3200 tweet. Bukan hanya digunakan pada tweet, twint juga bisa kita gunakan untuk melakukan scrapping pada user, followers, retweet dan sebagainya. Twint memanfaatkan operator pencarian twitter untuk memungkinkan proses penghapusan tweet dari user tertentu, memilih dan memilah informasi-informasi yang sensitif, termasuk email dan nomor telepon di dalamnya."],"metadata":{"id":"LTEUPOEWYv7P"}},{"cell_type":"markdown","source":["Data yang kita ambil ialah pemberitaan terbaru mengenai data dari negara Indonesia yang sedang diretas oleh orang luar negeri berinisial \"Bjorka\". Kata kunci yang digunakan 'databocor' pada **c.search**, menggunakan Pandas pada **c.Pandas**, menggunakan limitasi data sebanyak 80 data pada **c.Limit**, dengan menggunakan custom data yang dimasukkan ke csx dengan label Tweet dan data yang diambil tweet-nya saja. Output atau data akan dimasukkan ke dalam file **csv**."],"metadata":{"id":"YwMyrPjPVoDb"}},{"cell_type":"code","source":["c = twint.Config()\n","c.Search = 'databocor'\n","c.Pandas = True\n","c.Limit = 80\n","c.Store_csv = True\n","c.Custom[\"tweet\"] = [\"tweet\"]\n","c.Output = \"data.csv\"\n","twint.run.Search(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"1T1yFZ7hVs1e","executionInfo":{"status":"ok","timestamp":1663045089854,"user_tz":-420,"elapsed":2613,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"e8677637-d342-48a6-deca-ef45c4dad2f7"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["1569536578875281408 2022-09-13 04:00:55 +0000 <PostGorontalo> #DataBocor Mahfud Akui Data Pejabat Diretas Bjorka, Data Luhut Diposting di Telegram  https://t.co/VgqzoUf3da\n","1569511624184311811 2022-09-13 02:21:45 +0000 <fajaronline> BSSN Anggarkan Rp 1,8 Miliar untuk Buat Kolam Ranang, Fadli Zon: Lebih Penting dari Keamanan Siber  https://t.co/YVePTxowe4 #BSSN #DataBocor #FadliZon #KolamRenang\n","1569504645663571968 2022-09-13 01:54:02 +0000 <hitmeup_flora> @NadiBangsa @nvcarenvmind @opposite090l92 @bjorkanism Terus mau nyalahin siapa dong , ini udah nunjukin bahwa data kita gak di lindungi sama sekali wkwkwk daftar sim card-databocor-himbauan basi suruh ganti kata sandi.. ya udhlah ya , nyimak aja apa yang di perbuat si hacker itu 🤣\n","1569340924081340417 2022-09-12 15:03:27 +0000 <mohamadyani78> #Demo versi IT... #databocor #hackerbjorka panen fans, hingga jadi #trending di #Media masa dan #Viral di #Indonesia banyak #Data bocor. Masyarakat tak panik jika yang menjaga #data nya tidak kebobolan. #Pemerintah perlu solusi realistis.\n","1569335649844752385 2022-09-12 14:42:30 +0000 <fajaronline> Puan Desak Pemerintah Segera Audit Keamanan Siber  https://t.co/1zBpy5mKNX #AuditKeamanan #DataBocor #PuanMaharani\n","1569329728154406912 2022-09-12 14:18:58 +0000 <Evhylmardjani> Bjorka hecker.??? hahaha, kominfo butuh proyek broo udah brapatahun tidur tanpa asupan dana. Dari kmarin nyari duit ancam blokar blokir sosmed hahaha. Pake logika.  #Bjorka #bjorkanism #kominfo #hacker #hackerbjorka #databocor\n","1569317648055541760 2022-09-12 13:30:58 +0000 <KabarMalangCom> Pihak UB Koordinasi dengan BSSN Terkait Data Mahasiswa Alumi yang Tersebar, Terkait peretas yang di duga menyebarkan data alumni Mahasiswa S1 Universitas Brawijaya (UB) tahun 2020 #databocor #universitasbrawijaya #BSSN   https://t.co/LduVGn6Yyk\n","1569317010789781505 2022-09-12 13:28:26 +0000 <Andra_cukup> Data pribadi milik Menteri Koordinator Bidang Kemaritiman dan Investasi Luhut Binsar Pandjaitan dibocorkan oleh akun bernama Bjorka #bjorka #luhut #databocor #kebocorandata #luhutbinsarpandjaitan #viral #news #trending  Selengkapnya;  https://t.co/YUtRF8xw2d\n","1569306679162064902 2022-09-12 12:47:23 +0000 <PiResearchMedia> Some  Marketing Tips: (Grab it, Free of Cost 😁)  1. Know who you’re targeting  2. Create delightful products and practice smart marketing  3. Consumers are smarter than you think  4. Do SEO for your existing pages #research #MarketingStrategy #todaystip #databocor\n","1569305112757305344 2022-09-12 12:41:09 +0000 <intimeID> Instruksi Presiden Jokowi Tangani Dugaan Data Bocor  https://t.co/PoL1ESMpeY  #Bjorka #Jokowi #DataBocor\n","1569293918256205825 2022-09-12 11:56:40 +0000 <adjatwiratma> Data mu aman ? Data Pejabat Negara saja bocor, yang tanggung jawab siapa 😓 . . #mncnewsprime #adjatwiratma #mncnewschannelno1 @mncnewschannel w/ @bssn_ri @christinaaryani @sutadiheru #databocor #databocorlagi  https://t.co/TdBs0ZZx7U\n","1569283214677790723 2022-09-12 11:14:08 +0000 <intimeID> Marak Data Bocor, BSSN: Sistem Elektronik Aman Tidak Diserang  https://t.co/G0I1hc3x32  #DataBocor #BSSN #Bjorka\n","1569272022445993987 2022-09-12 10:29:40 +0000 <kompascom> Kasus Munir kembali menjadi perbincangan selepas hacker Bjorka mengunggah dokumen tentang sosok yang disebutnya sebagai pembunuh Munir. / #Hacker #Bjorka #Pemerintah #Indonesia #Publik #DataBocor #Kebocorandata #JernihMelihatDunia   Baca di  https://t.co/3WkngP1d5N  https://t.co/flpzeX93Po\n","1569267261801897985 2022-09-12 10:10:45 +0000 <insahu> G Plate itu bisa mundur nggak sih? #Bjorka  #databocor\n","1569262211318829056 2022-09-12 09:50:41 +0000 <KabarMalangCom> Data Mahasiswa Alumi UB Angkatan 2020, Tersebar, Peretas di duga menyebarkan data alumni Mahasiswa S1 Universitas Brawijaya (UB) tahun 2020 #databocor #alumniUB #angkatan2020   https://t.co/GyzyzTciZq\n","1569260413312966656 2022-09-12 09:43:32 +0000 <kompascom> Bjorka kemudian membagikan data pribadi yang diduga milik sejumlah pejabat publik Indonesia melalui grup Telegram miliknya. / #Hacker #Bjorka #Pemerintah #Indonesia #Kemenkominfo #Publik #DataBocor #Kebocorandata #JernihMelihatDunia   Baca di  https://t.co/3WkngP1d5N  https://t.co/9OLZdbfZQD\n","1569254795860639744 2022-09-12 09:21:13 +0000 <kompascom> Pada 9 September 2022, Bjorka kembali mengklaim memiliki dokumen surat-menyurat yang diduga milik Presiden Joko Widodo. / #Hacker #Bjorka #Pemerintah #Indonesia #Publik #DataBocor #Kebocorandata #JernihMelihatDunia   Baca di  https://t.co/3WkngP1d5N  https://t.co/4syRRHhnwc\n","1569254259421757440 2022-09-12 09:19:05 +0000 <kompascom> Pada 6 September 2022, Bjorka kembali membeberkan mengenai adanya kebocoran data sekitar 105 juta penduduk Indonesia. / #Hacker #Bjorka #Pemerintah #Indonesia #Kemenkominfo #Publik #DataBocor #Kebocorandata #JernihMelihatDunia   Baca di  https://t.co/3WkngP1d5N  https://t.co/ZmQRuU4Pzj\n","1569250594006892544 2022-09-12 09:04:31 +0000 <kompascom> 31 Agustus 2022, Bjorka di Breached Forums kembali mengklaim memiliki file terkompresi sebesar 18 GB berisi data kartu SIM dari pelanggan Indonesia. / #Hacker #Bjorka #Pemerintah #Indonesia #DataBocor #Kebocorandata #JernihMelihatDunia   Baca di  https://t.co/3WkngP1d5N  https://t.co/EeHfpG5UMS\n","1569249580491116544 2022-09-12 09:00:29 +0000 <kompascom> Pada 20 Agustus 2022, Bjorka mengumumkan bahwa dirinya menjual 26 juta data riwayat pencarian pengguna IndiHome di situs Breached Forums. / #Tren #Hacker #Bjorka #Pemerintah #Indonesia #Kemenkominfo #Publik #DataBocor #Jokowi #JernihMelihatDunia  https://t.co/ZPWKIpWNEt\n","1569248810949562370 2022-09-12 08:57:26 +0000 <kompascom> Sejumlah dugaan kebocoran data yang dibeberkan \"Hacker\" Bjorka, mulai dari data masyarakat Indonesia, data diri para pejabat negara, hingga kasus Munir. / #Tren #Hacker #Bjorka #Indonesia #DataBocor #Kebocorandata #JernihMelihatDunia   Baca di  https://t.co/3WkngP1d5N  https://t.co/n0x3qlQE1T\n","1569241908513325056 2022-09-12 08:30:00 +0000 <RRIPrograma3> BSSN Telusuri Dugaan Kebocoran Data Penyelenggara Sistem Elektronik   https://t.co/Fb5JpQ11pu #bssn #databocor\n","1569233379371134978 2022-09-12 07:56:07 +0000 <kompastv_jabar> Data Pribadi Diperjualbelikan di Forum Online  https://t.co/kfGGPCtxWl  #databocor #ktp #nik #kamujahat #bjorkanism #Online #Data #bandung #kompastvjabar  https://t.co/YsuZB0TiMC\n","1569220799890063360 2022-09-12 07:06:08 +0000 <fajaronline> Mahfud MD TegaskanData yang Diunggah Bjorka Tidak Ada Kaitannya dengan Data Rahasia Negara  https://t.co/8ptkDhmqhu #Bjorka #DataBocor #headline #MahfudMD\n","1569181251873165317 2022-09-12 04:28:59 +0000 <AliveGodX> #bjorkanism #JohnnyGPlate #databocor #OpenSource #Indonesia #AliveGod  https://t.co/NHPvvuTghh\n","1569178701321084929 2022-09-12 04:18:50 +0000 <muslimf> @cnbcindonesia  https://t.co/hWm91XmjjX  Data pribadi bocor kerap ditemui. Sayang, negara tidak bisa melindungi warganya karena UU terkait belum ada. Warga BSD pun melayangkan surat ke Jokowi. #daruratdigital #databocor #PDP\n","1569176632111566848 2022-09-12 04:10:37 +0000 <fajaronline> Data PSE Alami Kebocoran, Mardani Ali Sera: Ini Jadi Tamparan Atas Kewibawaan Pemerintah  https://t.co/Iz4AF3cpnV #DataBocor #headline #KebocoranData #MardaniAliSera\n","1569149253506977792 2022-09-12 02:21:50 +0000 <inilahbdgcom> Bjorkanism Tumbang, Muncul Akun Baru Hacker Bjorka di Twitter?  https://t.co/WCfo8RMnZz   #inilahbandung #bjorkanism #Bjorka #Hackers #databocor #kebocorandata #Indonesia #info #berita  https://t.co/ogH3FLV9gn\n","1569122166813368321 2022-09-12 00:34:12 +0000 <aciangfung>  https://t.co/jsYMyJebuj  #databocor\n","1569092651621957632 2022-09-11 22:36:55 +0000 <IkramMalvin> #HoaxDataBocor #LindungiDatamu #DatakuAman #databocor  https://t.co/kFeX9P36rz\n","1569092612476538884 2022-09-11 22:36:45 +0000 <IkramMalvin> #HoaxDataBocor #LindungiDatamu #DatakuAman #databocor  https://t.co/SsXSEkR9Ih\n","1569092574287400960 2022-09-11 22:36:36 +0000 <IkramMalvin> #HoaxDataBocor #LindungiDatamu #DatakuAman #databocor  https://t.co/YLLmJwBH3D\n","1569010742560686081 2022-09-11 17:11:26 +0000 <sunflowers_boys> Data bocor dan hacker itu mengungkapkan Kisah kelam bumi pertiwi ini -inisial G- #databocor #baubusuk #tercium\n","1568996325961924609 2022-09-11 16:14:09 +0000 <emhaidarr> Kedaulatan data; Negara tidak boleh kalah dengan para hacker!   #databocor\n","1568949986494414849 2022-09-11 13:10:01 +0000 <intimeID> Akun Hilang, Bjorka Muncul Lagi dan Membuka Data Menko Luhut  https://t.co/kF3Qbik1nh  #Bjorka #LuhutBinsarPandjaitan #DataBocor\n","1568895357962317826 2022-09-11 09:32:56 +0000 <suka_sibuk> Mulaii panikkk ygy sampek Pemerintah Indonesia collab ama BuzzerRP buat nyerang balik @bjorkanism  #bjorkanism  #databocor  https://t.co/A1MjCoYtLu\n","1568884680153530370 2022-09-11 08:50:30 +0000 <Assanditriputra> Analoginya ..kalian Mabok2an sama gank kalian...giliran bayar kita2 yg ga ikutan mabok2an disuruh ikut patungan!!! Ente sehat... #databocor #tanggungjawabbersama #ngeBO\n","1568884216703913986 2022-09-11 08:48:40 +0000 <lampungpost_> Badan Siber dan Sandi Negara (BSSN) menyampaikan telah melakukan penelusuran terhadap beberapa dugaan insiden kebocoran data terkait dokumen dan surat kepresidenan.  #BSSN #DataBocor #Kebocorandata #lampungpost  https://t.co/OfbP6URp0P.\n","1568882739365163010 2022-09-11 08:42:48 +0000 <NewsBreaking90> Berita terbaru kebocoran data  https://t.co/bD3lej0UZf #databocor  #Viral  #TikTok  https://t.co/wlv8izL3MX\n","1568882610084139008 2022-09-11 08:42:17 +0000 <mataharitimoer> lapor ke kominfo ❎ lapor ke bssn ❎ lapor ke sini ✅  #databocor #databreach  https://t.co/WSbZ68GmW2\n","1568879478067335171 2022-09-11 08:29:50 +0000 <AmadoDamn> Kenapa nama gw ada di daftar anggota partai politik?  Efek data komintol bocor?  Atau gmn?  #Bjorka #Kominfo #databocor  https://t.co/hgKSOb2Q5m\n","1568877190363910144 2022-09-11 08:20:45 +0000 <chuakzz17806911> data bocor? orang Kominfo bingung? ya iyalah bingung, masuk kerja aja lewat orang dalam chuakzzzz #databocor\n","1568872075728941057 2022-09-11 08:00:25 +0000 <JNursiyono> Berikut analisis sentimen kebijakan kenaikan harga BBM selama 26 Agustus -10 September 2022. #TolakTerusKenaikanBBM #TolakKenaikanBBM #TolakKenaikanHargaBBM #BBM #bbmnaik #Data #DataScience #BigData #tiktokhot #Viral #TikTokLive #databocor #LoveStory #indoviral #earthquake  https://t.co/89kN4rcNAH\n","1568864922292944896 2022-09-11 07:32:00 +0000 <holopiscom> Anggota Komisi I DPR RI, Sukamta menyampaikan bahwa Rancangan Undang-Undang Perlindungan Data Pribadi (RUU PDP) akan segera disahkan menjadi undang-undang (UU) dalam waktu dekat. @DPR_RI  #RUUPDP #databocor   https://t.co/5GW6Xugplh\n","1568861939660636161 2022-09-11 07:20:09 +0000 <intimeID> Kemarin Johny, Hari Ini Bjorka Sapa Puan Hingga Denny Siregar  https://t.co/iFihcJV8oz  #Bjorka #Bjorkanism #Doxing #PuanMaharani #DataBocor\n","1568837317372280834 2022-09-11 05:42:18 +0000 <bj669ml> paling gampang cek aja instansi2 yang datanya bocor pakai isp apa ? apakah isp tsbt pernah bocor datanya ? termasuk ip adresess nya ? #databocor\n","1568824913552879620 2022-09-11 04:53:01 +0000 <Riyan_ardd> Penasaran ama grup wa kominfo ama pemerintahan wkwkwk  #Bjorka  #bjorkanism  #munir  #databocor\n","1568817939650052098 2022-09-11 04:25:18 +0000 <Koakset> Eh penonton... katanya ada yang panik sama keberpihakan masyarakat ke hacker ilegal, lah situ gagal jadi sosok pahlawan yg pro rakyat sih 😂  #koakset #komikakalsehat #vforvendetta #stopbeinganidiot #kominfo #databocor #bjorka #hackerindonesia #hackerbjorka  https://t.co/874sVfwjnQ\n","1568745497527201792 2022-09-10 23:37:27 +0000 <afi_kusumo> Lebih baik telat daripada kagak sama sekali   #databocor\n","1568612105242443778 2022-09-10 14:47:23 +0000 <tyskmtgts> Karena data pribadi Pakde sm Wapres dah bocor sebelumnya? #Bjorka #databocor\n","1568608970428006400 2022-09-10 14:34:56 +0000 <fajaronline> Kisruh Data Bocor, BSSN Sebut masih Lakukan Langkah Ini …  https://t.co/9CQF4ccdkE #DataBocor #Hacker\n","1568594632917028866 2022-09-10 13:37:58 +0000 <akhmadf21>  https://t.co/ndSCQjnxkA #Bjorka #DokumenPresiden #klaim #DataBocor\n","1568582888060514306 2022-09-10 12:51:18 +0000 <cameoproject_> Haduh.... Jadi apa nih pak fungsi kominfo? Mana gak cuman sekali lagi bocornya! 😵‍💫  Tonton full videonya di YT Cameo, link di bio! ( https://t.co/ZkTp0YAJcT)  #cameoproject #kominfo #databocor #hacker  https://t.co/zinaGKxayD\n","1568559236287975426 2022-09-10 11:17:19 +0000 <Alexand14390361> Mengapa rakyat indonesia memuja-muja Bjorka padahal dia ngehack dan membocorkan data pribadi mereka sendiri?dan membully rakyat indonesia sendiri?  #kominfo #databocor\n","1568558682534985728 2022-09-10 11:15:06 +0000 <Manusia90528218> Ketika data rakyat dicuri mereka tidak peduli namun ketika data mereka sendiri diambil mereka panik, indahnya negri ku. Pejabat nomor 1, rakyat no 100.  September,2022. #hackerbjorka #Indonesia #databocor\n","1568555006978150402 2022-09-10 11:00:30 +0000 <holopiscom> Badan Intelijen Negara (BIN) akhirnya angkat bicara terkait isu kebocoran ribuan surat yang dikirim oleh pihaknya kepada Presiden Joko Widodo (Jokowi). @binofficial_ri  @setpresRI #DataBocor  https://t.co/LlVVGBkeLd\n","1568554883032272902 2022-09-10 11:00:01 +0000 <rocknewsnetwork> Bjorka meresahkan 😓  #supportlocal #foryourpage #tiktok #k #wonderfullombok #beritahariini #wonderfullombok #beritahariini #mediasosial #repostplus #holareels #reelsindonesia #videooftheday #newstoday #newsofheday #hackerbjorka #Bjorka #databocor  https://t.co/o6T9XMakra\n","1568538524856758275 2022-09-10 09:55:01 +0000 <intimeID> Kasetpres Bantah Data Surat dan Dokumen Presiden Bocor  https://t.co/sJjfIWTYUg  #Bjorka #DataBocor #SuratPresiden\n","1568531600966664192 2022-09-10 09:27:30 +0000 <kompascom> 7. \"Saya rasa penegak hukum akan melakukan tindakan hukum. Nanti akan ada pernyataan resmi pejabat terkait,\" ucap Kepala Sekretariat Presiden Heru Budi Hartono. Simak informasi selengkapnya dalam artikel berikut. * #BIN #DataBocor #Bjorka  https://t.co/q1AngfaJKI\n","1568530594249822208 2022-09-10 09:23:30 +0000 <kompascom> 6. Juru Bicara BIN Wawan Hari Purwanto juga menepis kabar dokumen atau surat-surat dari BIN untuk Presiden telah bocor. Wawan menegaskan, surat untuk presiden diberi pengaman khusus. * #BIN #DataBocor #Bjorka  https://t.co/PHFYuhIWyQ\n","1568529084375875585 2022-09-10 09:17:30 +0000 <kompascom> 5. Kepala Sekretariat Presiden Heru Budi Hartono memastikan, tidak ada satu pun dokumen surat menyurat Presiden Joko Widodo yang diretas. * #BIN #DataBocor #Bjorka  https://t.co/6QM0caZ6Yb\n","1568528138535321601 2022-09-10 09:13:44 +0000 <kompascom> 4. Dokumen tersebut antara lain “Permohonan Dukungan Sarana dan Prasarana\", \"Surat Rahasia kepada Presiden dalam amplop tertutup\" dan \"Gladi Bersih dan Pelaksanaan Upacara Bendera pada Peringatan HUT ke-74 Tahun 2019\".* #BIN #DataBocor #Bjorka  https://t.co/ROemZ3WHTt\n","1568526567759831045 2022-09-10 09:07:30 +0000 <kompascom> 3. Dokumen-dokumen periode 2018-2021 itu diunggah di situs  https://t.co/RtNzC8sEPw dan salah satu dokumen berasal dari Badan Intelijen Negara (BIN) untuk Presiden Jokowi. * #BIN #DataBocor #Bjorka  https://t.co/q1AngfaJKI\n","1568524932350447616 2022-09-10 09:01:00 +0000 <kompascom> 2. Dalam unggahannya, hacker tersebut menjelaskan bahwa telah mengunggah total 679.180 dokumen berukuran 40 MB. * #BIN #DataBocor #Bjorka  https://t.co/WglwlnIMkn\n","1568523925214085120 2022-09-10 08:57:00 +0000 <kompascom> 1. Kali ini, hacker mengklaim telah memiliki surat dan dokumen yang ditujukan ke Presiden Republik Indonesia. Disebutkan bahwa dokumen untuk Kepala Negara itu dibocorkan ke deep web oleh aktor jahat bernama Bjorka. * #BIN #DataBocor #Bjorka  https://t.co/PHFYuhIWyQ\n","1568523302158893057 2022-09-10 08:54:31 +0000 <jalalsangar> Mosok bjorka orang Indonesia yang bisa geser satelit #databocor\n","1568522962776752128 2022-09-10 08:53:10 +0000 <kompascom> {Thread}  Ramai soal Surat Rahasia untuk Presiden Diklaim Bocor, BIN Tegaskan Hoaks * #BIN #DataBocor #Bjorka    https://t.co/PHFYuhJuoo\n","1568466498523656196 2022-09-10 05:08:48 +0000 <OngisSiang> SALE SALE SALE  HOODIE JUMPER BY TOP TEN  SIZE M LD116/P68 WARNA PEKAT LIKE NEW  HARGA 115K AJA FREEONG IN SHOPEE 😀 #bjorka #databocor #ceritahoror #sarapan #demobbm #TolakKenaikanBBM #ceritahaid #ceritanakal #diskongede #jakartaselatan #demojakarta  https://t.co/BcpWKYpTQY\n","1568267326126198784 2022-09-09 15:57:22 +0000 <asal_info> Apalagi ini?? Rentan bgt data di Indonesia (kalau valid)  https://t.co/tmUuGnRLxs  #kpu #databocor #data #Hackers\n","1568111235811667969 2022-09-09 05:37:07 +0000 <langittluas> Tuh kan bocor lagi. Nambalnya pake apa sih? Dah coba Aquaproof belum? Coba dah, dijamin no wahid  #databocor\n","1568078832007278594 2022-09-09 03:28:21 +0000 <seekerzl> Sekarang berada di pasaran ya gaes ya   Menkominfo idiot #databocor  https://t.co/P8nqt9sG6P\n","1568062895019413504 2022-09-09 02:25:02 +0000 <exsantrii> Bentar lagi viral pastii, setelah bocor 1,3M SIMCARD bocor. Ini anget banget soalnya tadi dini hari jam 01. Data Ijasah lengkat sama KTP, Akta dan KK. Dijual $100. #kominfo #bocor #databocor  https://t.co/GOYkeWlWp0\n","1568041903815557121 2022-09-09 01:01:37 +0000 <langittluas> Kasih tau bang, badeur banget jadi bocah yak. Malah tunjuk sana tunjuk sini. Kata gw mah, kalo data bocor tinggal dikasih Aquaproof aja beres. Genteng rumah gw juga dah ga bocor lagi...alhamdulilah aman. Dah cobain dah.  #databocor #kominfo #kpu #konoha  https://t.co/WCzDU2ENrD\n","1567907584350502914 2022-09-08 16:07:53 +0000 <Anak_Bontot_9> @ShopeeID Bangsat siapa pelakunya Jauh tidak Sama Yang Punya Toko? #ShopeePelindungSellerAnjenk #DataBocor  https://t.co/N3ZpX4xntj\n","1567899667089997825 2022-09-08 15:36:25 +0000 <librarynanang> Harga minyak dunia terjun bebas, harga BBM Nasional meroket  Hacker dunia iseng, data Nasional ludes  #BBMNaik_RakyatMenjerit  #databocor\n","1567893466474229762 2022-09-08 15:11:47 +0000 <OngisSiang> SALE SALE SALE  CREWNECK RAJUT BY UNIQLO  SIZE M LD 126/P 65 FULL RAJUT KEPANG ACCENT KEPANG BESAR LIKE NEW  SALE JADI 99K FREEONGKIR IN SHOPEE😄 #bbmnaik #kominfo #databocor #sambo #nikbocor #Demomahasiswa #demobbm  https://t.co/p4ghZ1P9AC\n","1567848564604420096 2022-09-08 12:13:21 +0000 <BlockmanOppi> @kemkominfo Ya inilah negara konoha #databocor #kominfo semua pekerja semua orang tomlol gak tahu teknologi.\n","1567768882886373377 2022-09-08 06:56:44 +0000 <GTVID_News> Situs Forum Hacker Penjual Data  https://t.co/5kPDjeoGpN  #GTVNews #GTV #Hacker #PLN #IndiHome #JasaMarga #KebocoranData #DataBocor  https://t.co/Lbb4t3ZEDZ\n","1567714881767604224 2022-09-08 03:22:09 +0000 <Anak_Bontot_9> @agitavia @hhaeeew Hati hati no penipu  Dengan modus mengirimkan barang menggunakan akun fake lalu belanja di toko sendiri. Dgn alamat tujuan acak/ dapat dr toko sebelah . Lewat COD #DataBocor  https://t.co/p1flQrVaBs\n","1567697504694849536 2022-09-08 02:13:06 +0000 <Alsyundawy> Masa cuma bilang data bukan bocor dari tempat lo lalu masalahnya selesai @kemkominfo. Lo kan yg wajibkan kita kasih data dan sekarang datanya bocor. Dasar sekate² , ente suka ngandi² , ente nih kadang² seringnya gak ngotak, #BlokirKominfo #databocor cc @jokowi @PolhukamRI @DPR_RI\n"]}]},{"cell_type":"markdown","source":["Membuka file **csv** yang sudah dilabeli secara manual dengan 3 kelas yaitu positif, netral, dan negatif. "],"metadata":{"id":"ce9U22XNXP8B"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Web Mining/webmining"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6raXRMW-j3a4","executionInfo":{"status":"ok","timestamp":1663084507920,"user_tz":-420,"elapsed":6,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"a51733af-0791-4dc4-91f3-c40cd35ef4b7"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Web Mining/webmining\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_csv('dataBocor.csv')\n","data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"zJ1x9J8sWRuq","executionInfo":{"status":"ok","timestamp":1663084512385,"user_tz":-420,"elapsed":1421,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"b4e0ec72-47fe-4f6a-aa52-7d27b0c309f3"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                tweet    label\n","0   #DataBocor Mahfud Akui Data Pejabat Diretas Bj...   netral\n","1   BSSN Anggarkan Rp 1,8 Miliar untuk Buat Kolam ...  positif\n","2   @NadiBangsa @nvcarenvmind @opposite090l92 @bjo...   netral\n","3   #Demo versi IT... #databocor #hackerbjorka pan...  positif\n","4   Puan Desak Pemerintah Segera Audit Keamanan Si...  positif\n","..                                                ...      ...\n","75  SALE SALE SALE  CREWNECK RAJUT BY UNIQLO  SIZE...   netral\n","76  @kemkominfo Ya inilah negara konoha #databocor...  negatif\n","77  Situs Forum Hacker Penjual Data  https://t.co/...   netral\n","78  @agitavia @hhaeeew Hati hati no penipu  Dengan...   netral\n","79  Masa cuma bilang data bukan bocor dari tempat ...  negatif\n","\n","[80 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-824ca998-e5a9-4a3c-9025-2cb0c8a3833a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>#DataBocor Mahfud Akui Data Pejabat Diretas Bj...</td>\n","      <td>netral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BSSN Anggarkan Rp 1,8 Miliar untuk Buat Kolam ...</td>\n","      <td>positif</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>@NadiBangsa @nvcarenvmind @opposite090l92 @bjo...</td>\n","      <td>netral</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>#Demo versi IT... #databocor #hackerbjorka pan...</td>\n","      <td>positif</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Puan Desak Pemerintah Segera Audit Keamanan Si...</td>\n","      <td>positif</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>SALE SALE SALE  CREWNECK RAJUT BY UNIQLO  SIZE...</td>\n","      <td>netral</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>@kemkominfo Ya inilah negara konoha #databocor...</td>\n","      <td>negatif</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>Situs Forum Hacker Penjual Data  https://t.co/...</td>\n","      <td>netral</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>@agitavia @hhaeeew Hati hati no penipu  Dengan...</td>\n","      <td>netral</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>Masa cuma bilang data bukan bocor dari tempat ...</td>\n","      <td>negatif</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>80 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-824ca998-e5a9-4a3c-9025-2cb0c8a3833a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-824ca998-e5a9-4a3c-9025-2cb0c8a3833a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-824ca998-e5a9-4a3c-9025-2cb0c8a3833a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Matrix Term Frequent"],"metadata":{"id":"J2TDDewIXglX"}},{"cell_type":"markdown","source":["\n",">**NLTK** adalah singkatan dari Natural Language Tool Kit, yaitu sebuah library yang digunakan untuk membantu kita dalam bekerja dengan teks. Library ini memudahkan kita untuk memproses teks seperti melakukan classification, tokenization, stemming, tagging, parsing, dan semantic reasoning.\n","\n",">**Python Sastrawi** adalah pengembangan dari proyek PHP Sastrawi. Python Sastrawi merupakan library sederhana yang dapat mengubah kata berimbuhan bahasa Indonesia menjadi bentuk dasarnya. Sastrawi juga dapat diinstal melalui “pip”\n","\n"],"metadata":{"id":"sHjoQc74mups"}},{"cell_type":"code","source":["!pip install nltk\n","!pip install Sastrawi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U87gJEpdkaEu","executionInfo":{"status":"ok","timestamp":1663084408721,"user_tz":-420,"elapsed":8247,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"bdf23a93-7324-424a-8827-12eca0d7900c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Sastrawi\n","  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 7.9 MB/s \n","\u001b[?25hInstalling collected packages: Sastrawi\n","Successfully installed Sastrawi-1.0.1\n"]}]},{"cell_type":"markdown","source":["Pembuatan matriks menggunakan module pandas beserta numpy agar matriks yang dibuat sesuai dengan kebutuhan.\n","\n",">**Pandas** adalah sebuah library di Python yang berlisensi BSD dan open source yang menyediakan struktur data dan analisis data yang mudah digunakan. Pandas biasa digunakan untuk membuat tabel, mengubah dimensi data, mengecek data, dan lain sebagainya. Struktur data dasar pada Pandas dinamakan DataFrame, yang memudahkan kita untuk membaca sebuah file dengan banyak jenis format seperti file .txt, .csv, dan .tsv. Fitur ini akan menjadikannya table dan juga dapat mengolah suatu data dengan menggunakan operasi seperti join, distinct, group by, agregasi, dan teknik lainnya yang terdapat pada SQL.\n","\n",">**NumPy** merupakan singkatan dari Numerical Python. NumPy merupakan salah satu library Python yang berfungsi untuk proses komputasi numerik. NumPy memiliki kemampuan untuk membuat objek N-dimensi array. Array merupakan sekumpulan variabel yang memiliki tipe data yang sama. Kelebihan dari NumPy Array adalah dapat memudahkan operasi komputasi pada data, cocok untuk melakukan akses secara acak, dan elemen array merupakan sebuah nilai yang independen sehingga penyimpanannya dianggap sangat efisien."],"metadata":{"id":"WrkJd4_8qA0q"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import numpy as np\n","\n","import nltk\n","nltk.download('punkt')\n","import string\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjHz31vpkfS2","executionInfo":{"status":"ok","timestamp":1663084440899,"user_tz":-420,"elapsed":398,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"e4e1f63e-d01d-4f3e-dca0-d9f00b21e0f4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["**Function Remove Stopwords** berguna menghapus kata-kata yang tidak diperlukan dalam proses nantinya,sehingga dapat mempercepat proses VSM. Kita meenggunakan kumpulan stopword dari github yang berjumlah sekitar 700 kata. "],"metadata":{"id":"Auo8BTinq5Dz"}},{"cell_type":"code","source":["def remove_stopwords(text):\n","    with open('/content/drive/MyDrive/Web Mining/webmining/stopwords.txt') as f:\n","        stopwords = f.readlines()\n","        stopwords = [x.strip() for x in stopwords]\n","    \n","    text = nltk.word_tokenize(text)\n","    text = [word for word in text if word not in stopwords]\n","                     \n","    return text"],"metadata":{"id":"jZo-mDRbknxm","executionInfo":{"status":"ok","timestamp":1663084543626,"user_tz":-420,"elapsed":394,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**Stemming** merupakan proses mengubah kata dalam bahasa Indonesia ke akar katanya atau tidak ada kata yang berimbuhan pada awal maupun akhir kata serta tidak ada kata yang berulangan misalkan 'anak perempuan berjalan - jalan' menjadi 'anak perempuan jalan'"],"metadata":{"id":"y7wjjFNbrPJ0"}},{"cell_type":"code","source":["def stemming(text):\n","    factory = StemmerFactory()\n","    stemmer = factory.create_stemmer()\n","    \n","    result = [stemmer.stem(word) for word in text]\n","    \n","    return result"],"metadata":{"id":"kzjpKL-Pkoi-","executionInfo":{"status":"ok","timestamp":1663084544718,"user_tz":-420,"elapsed":404,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["**Preprocessing** terdiri dari beberapa tahapan yang terdiri dari :\n","\n","\n","> * Mengubah Text menjadi huruf kecil\n","* Menghilangkan Url didalam Text\n","* Mengubah/menghilangkan tanda (misalkan garis miring menjadi spasi)\n","* Melakukan tokenization kata dan Penghapusan Kata yang tidak digunakan\n","* Memfilter kata dari tanda baca\n","* Mengubah kata dalam bahasa Indonesia ke akar katanya\n","* Menghapus String kosong"],"metadata":{"id":"Zileo-VKr4ub"}},{"cell_type":"code","source":["def preprocessing(text):\n","    #case folding\n","    text = text.lower()\n","    #remove urls\n","    text = re.sub('http\\S+', '', text)\n","    #replace weird characters\n","    text = text.replace('“', '\"')\n","    text = text.replace('”', '\"')\n","    text = text.replace('-', ' ')\n","    #tokenization and remove stopwords\n","    text = remove_stopwords(text)\n","    #remove punctuation    \n","    text = [''.join(c for c in s if c not in string.punctuation) for s in text]    \n","    #stemming\n","    text = stemming(text)\n","    #remove empty string\n","    text = list(filter(None, text))\n","    return text"],"metadata":{"id":"ktTxMpynkqJo","executionInfo":{"status":"ok","timestamp":1663084546818,"user_tz":-420,"elapsed":406,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Membuat matriks term frekuensi yang sudah dilakukan **Preprocessing** pada data crawling. Data yang kosong diisi dengan angka 0."],"metadata":{"id":"LcVvx7UCsuer"}},{"cell_type":"code","source":["tf = pd.DataFrame()\n","for i,v in enumerate(data['tweet']):\n","    cols = [\"Doc \" + str(i+1)]    \n","    doc = pd.DataFrame.from_dict(nltk.FreqDist(preprocessing(v)), orient='index',columns=cols)\n","    tf = pd.concat([tf, doc], axis=1, sort=False)"],"metadata":{"id":"W3-eN3CZktO_","executionInfo":{"status":"ok","timestamp":1663084649175,"user_tz":-420,"elapsed":100521,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["tf.index.name = 'Term'\n","tf = pd.concat([tf], axis=1, sort=False)\n","tf = tf.fillna(0)\n","tf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":516},"id":"lsobzGH0kure","executionInfo":{"status":"ok","timestamp":1663084747723,"user_tz":-420,"elapsed":24,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"e3ef1d8d-6600-45aa-8b03-1c8e54ba08de"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               Doc 1  Doc 2  Doc 3  Doc 4  Doc 5  Doc 6  Doc 7  Doc 8  Doc 9  \\\n","Term                                                                           \n","databocor        1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0    1.0   \n","mahfud           1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","aku              1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","data             2.0    0.0    1.0    2.0    0.0    0.0    2.0    1.0    0.0   \n","jabat            1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","...              ...    ...    ...    ...    ...    ...    ...    ...    ...   \n","kadang           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","ngotak           0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","blokirkominfo    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","cc               0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","polhukamri       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n","\n","               Doc 10  ...  Doc 71  Doc 72  Doc 73  Doc 74  Doc 75  Doc 76  \\\n","Term                   ...                                                   \n","databocor         1.0  ...     1.0     1.0     1.0     1.0     1.0     1.0   \n","mahfud            0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","aku               0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","data              1.0  ...     0.0     1.0     1.0     0.0     1.0     0.0   \n","jabat             0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","...               ...  ...     ...     ...     ...     ...     ...     ...   \n","kadang            0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","ngotak            0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","blokirkominfo     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","cc                0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","polhukamri        0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n","\n","               Doc 77  Doc 78  Doc 79  Doc 80  \n","Term                                           \n","databocor         1.0     1.0     1.0     1.0  \n","mahfud            0.0     0.0     0.0     0.0  \n","aku               0.0     0.0     0.0     0.0  \n","data              0.0     1.0     0.0     3.0  \n","jabat             0.0     0.0     0.0     0.0  \n","...               ...     ...     ...     ...  \n","kadang            0.0     0.0     0.0     1.0  \n","ngotak            0.0     0.0     0.0     1.0  \n","blokirkominfo     0.0     0.0     0.0     1.0  \n","cc                0.0     0.0     0.0     1.0  \n","polhukamri        0.0     0.0     0.0     1.0  \n","\n","[634 rows x 80 columns]"],"text/html":["\n","  <div id=\"df-df366436-5d97-4024-b6c1-40ab4518e313\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Doc 1</th>\n","      <th>Doc 2</th>\n","      <th>Doc 3</th>\n","      <th>Doc 4</th>\n","      <th>Doc 5</th>\n","      <th>Doc 6</th>\n","      <th>Doc 7</th>\n","      <th>Doc 8</th>\n","      <th>Doc 9</th>\n","      <th>Doc 10</th>\n","      <th>...</th>\n","      <th>Doc 71</th>\n","      <th>Doc 72</th>\n","      <th>Doc 73</th>\n","      <th>Doc 74</th>\n","      <th>Doc 75</th>\n","      <th>Doc 76</th>\n","      <th>Doc 77</th>\n","      <th>Doc 78</th>\n","      <th>Doc 79</th>\n","      <th>Doc 80</th>\n","    </tr>\n","    <tr>\n","      <th>Term</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>databocor</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>mahfud</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>aku</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>data</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>jabat</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>kadang</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>ngotak</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>blokirkominfo</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>cc</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>polhukamri</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>634 rows × 80 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df366436-5d97-4024-b6c1-40ab4518e313')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-df366436-5d97-4024-b6c1-40ab4518e313 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df366436-5d97-4024-b6c1-40ab4518e313');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["## Mutual Information"],"metadata":{"id":"O0n9jsWuYDqA"}},{"cell_type":"code","source":["!pip install -U scikit-learn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7GCYKBnvk2DU","executionInfo":{"status":"ok","timestamp":1663084747721,"user_tz":-420,"elapsed":4796,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"4757b622-b1ca-4d2b-a67a-b1699224aff7"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n"]}]},{"cell_type":"code","source":["train = tf.iloc[:,:len(data)]\n","test = tf.iloc[:,len(data):]"],"metadata":{"id":"wazbFAsmk22g","executionInfo":{"status":"ok","timestamp":1663084751684,"user_tz":-420,"elapsed":6,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["cols = train.columns\n","df = pd.DataFrame(train[cols].gt(0).sum(axis=1), columns=['Document Frequency'])\n","idf = np.log10(len(cols)/df)\n","idf.columns = ['Inverse Document Frequency']\n","idf = pd.concat([df, idf], axis=1)"],"metadata":{"id":"is--qwhAk7yf","executionInfo":{"status":"ok","timestamp":1663084753085,"user_tz":-420,"elapsed":6,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["idf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"id":"ICKtUZaFzW9h","executionInfo":{"status":"ok","timestamp":1663084755578,"user_tz":-420,"elapsed":15,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"10897854-862e-4222-c4a9-aa9e871d8c5e"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               Document Frequency  Inverse Document Frequency\n","Term                                                         \n","databocor                      80                    0.000000\n","mahfud                          2                    1.602060\n","aku                             1                    1.903090\n","data                           40                    0.301030\n","jabat                           6                    1.124939\n","...                           ...                         ...\n","kadang                          1                    1.903090\n","ngotak                          1                    1.903090\n","blokirkominfo                   1                    1.903090\n","cc                              1                    1.903090\n","polhukamri                      1                    1.903090\n","\n","[634 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-29b5953b-bbb9-4a1b-b822-f395cbe05f9b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Document Frequency</th>\n","      <th>Inverse Document Frequency</th>\n","    </tr>\n","    <tr>\n","      <th>Term</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>databocor</th>\n","      <td>80</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mahfud</th>\n","      <td>2</td>\n","      <td>1.602060</td>\n","    </tr>\n","    <tr>\n","      <th>aku</th>\n","      <td>1</td>\n","      <td>1.903090</td>\n","    </tr>\n","    <tr>\n","      <th>data</th>\n","      <td>40</td>\n","      <td>0.301030</td>\n","    </tr>\n","    <tr>\n","      <th>jabat</th>\n","      <td>6</td>\n","      <td>1.124939</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>kadang</th>\n","      <td>1</td>\n","      <td>1.903090</td>\n","    </tr>\n","    <tr>\n","      <th>ngotak</th>\n","      <td>1</td>\n","      <td>1.903090</td>\n","    </tr>\n","    <tr>\n","      <th>blokirkominfo</th>\n","      <td>1</td>\n","      <td>1.903090</td>\n","    </tr>\n","    <tr>\n","      <th>cc</th>\n","      <td>1</td>\n","      <td>1.903090</td>\n","    </tr>\n","    <tr>\n","      <th>polhukamri</th>\n","      <td>1</td>\n","      <td>1.903090</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>634 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29b5953b-bbb9-4a1b-b822-f395cbe05f9b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-29b5953b-bbb9-4a1b-b822-f395cbe05f9b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-29b5953b-bbb9-4a1b-b822-f395cbe05f9b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["df_x = data.iloc[:, 1:]\n","df_y = data.iloc[:, 0]"],"metadata":{"id":"tU6GGcXklF0u","executionInfo":{"status":"ok","timestamp":1663084874898,"user_tz":-420,"elapsed":433,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,Y_train,Y_test=train_test_split(df.drop(labels=['Document Frequency'],axis=1),\n","                                               df['Document Frequency'],\n","                                               test_size=0.3,\n","                                               random_state=0)\n","\n","from sklearn.feature_selection import mutual_info_classif\n","mutual_info=mutual_info_classif(df_x,df_y)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"ett2wNPylIVE","executionInfo":{"status":"error","timestamp":1663085099259,"user_tz":-420,"elapsed":362,"user":{"displayName":"Faridz Nur Firdausy S N 19-084","userId":"00266508585162115821"}},"outputId":"86796db7-1042-4fde-a3ec-b8161c3c57ff"},"execution_count":24,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-9a226bb80a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmutual_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    462\u001b[0m     \"\"\"\n\u001b[1;32m    463\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_estimate_mi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    254\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m         \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'netral'"]}]}]}